{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment-Analyse\n",
    "\n",
    "Create virtual environment (once)\n",
    "\n",
    "```sh\n",
    "conda create -n sentiment python=3.11 pip\n",
    "```\n",
    "\n",
    "Activate environment\n",
    "\n",
    "```sh\n",
    "conda activate sentiment\n",
    "```\n",
    "\n",
    "Install modules (once)\n",
    "\n",
    "```sh\n",
    "pip install jupyter ipykernel pandas selenium webdriver-manager beautifulsoup4 nltk spacy wordcloud matplotlib altair\n",
    "```\n",
    "\n",
    "Import modules (always)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m stopwords\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokenize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m word_tokenize\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "# Import der erforderlichen Bibliotheken gemäß PEP8\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from spacytextblob.spacytextblob import SpacyTextBlob\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import altair as alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Herunterladen der NLTK-Ressourcen\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Zusätzliche Stopwörter definieren\n",
    "additional_stopwords = set([\n",
    "    'studium', 'studiengang', 'hochschule', 'uni', 'universität', 'semester', \n",
    "    'student', 'studieren', 'studierende', 'fach', 'lehrveranstaltung', 'professor', \n",
    "    'dozent', 'viele', 'dabei', 'ab', 'jedoch', 'auch', 'immer', 'während', 'mehr', \n",
    "    'bisher', 'obwohl', 'zudem', 'hochschule', 'studium', 'studiengang', 'semester', 'erfahrungsbericht', \n",
    "    'weiterlesen', 'dozenten', 'gut', 'viele', 'immer', 'gibt', 'hdm', \n",
    "    'macromedia', 'mittweida', 'vorlesungen',  'aber', 'alle', 'allem', 'allen', 'aller', 'alles', 'als', 'also', 'am', 'an', 'ander', 'andere', \n",
    "    'anderem', 'anderen', 'anderer', 'anderes', 'anderm', 'andern', 'anderr', 'anders', 'auch', \n",
    "    'auf', 'aus', 'bei', 'bin', 'bis', 'bist', 'da', 'damit', 'dann', 'der', 'den', 'des', 'dem', \n",
    "    'die', 'das', 'dass', 'daß', 'derselbe', 'derselben', 'denselben', 'desselben', 'demselben', \n",
    "    'dieselbe', 'dieselben', 'dasselbe', 'dazu', 'dein', 'deine', 'deinem', 'deinen', 'deiner', \n",
    "    'deines', 'denn', 'derer', 'dessen', 'dich', 'dir', 'du', 'dies', 'diese', 'diesem', 'diesen', \n",
    "    'dieser', 'dieses', 'doch', 'dort', 'durch', 'ein', 'eine', 'einem', 'einen', 'einer', 'eines', \n",
    "    'einig', 'einige', 'einigem', 'einigen', 'einiger', 'einiges', 'einmal', 'er', 'ihn', 'ihm', \n",
    "    'es', 'etwas', 'euer', 'eure', 'eurem', 'euren', 'eurer', 'eures', 'für', 'gegen', 'gewesen', \n",
    "    'hab', 'habe', 'haben', 'hat', 'hatte', 'hatten', 'hier', 'hin', 'hinter', 'ich', 'mich', \n",
    "    'mir', 'ihr', 'ihre', 'ihrem', 'ihren', 'ihrer', 'ihres', 'euch', 'im', 'in', 'indem', 'ins', \n",
    "    'ist', 'jede', 'jedem', 'jeden', 'jeder', 'jedes', 'jene', 'jenem', 'jenen', 'jener', 'jenes', \n",
    "    'jetzt', 'kann', 'kein', 'keine', 'keinem', 'keinen', 'keiner', 'keines', 'können', 'könnte', \n",
    "    'machen', 'man', 'manche', 'manchem', 'manchen', 'mancher', 'manches', 'mein', 'meine', \n",
    "    'meinem', 'meinen', 'meiner', 'meines', 'mit', 'muss', 'musste', 'nach', 'nicht', 'nichts', \n",
    "    'noch', 'nun', 'nur', 'ob', 'oder', 'ohne', 'sehr', 'sein', 'seine', 'seinem', 'seinen', \n",
    "    'seiner', 'seines', 'selbst', 'sich', 'sie', 'ihnen', 'sind', 'so', 'solche', 'solchem', \n",
    "    'solchen', 'solcher', 'solches', 'soll', 'sollte', 'sondern', 'sonst', 'über', 'um', 'und', \n",
    "    'uns', 'unsere', 'unserem', 'unseren', 'unser', 'unseres', 'unter', 'viel', 'vom', 'von', \n",
    "    'vor', 'während', 'war', 'waren', 'warst', 'was', 'weg', 'weil', 'weiter', 'welche', 'welchem', \n",
    "    'welchen', 'welcher', 'welches', 'wenn', 'werde', 'werden', 'wie', 'wieder', 'will', 'wir', \n",
    "    'wird', 'wirst', 'wo', 'wollen', 'wollte', 'würde', 'würden', 'zu', 'zum', 'zur', 'zwar', \n",
    "    'zwischen'\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Textbereinigungsfunktion\n",
    "def clean_text(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('german')]\n",
    "    tokens = [word for word in tokens if word not in additional_stopwords]\n",
    "    tokens = [word for word in tokens if word.isalnum()]\n",
    "    return ' '.join(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Funktion zur Generierung von Wortwolken\n",
    "def generate_wordcloud(text, title):\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Lade die CSV-Dateien\n",
    "mittweida_df = pd.read_csv('medienmanagement_mittweida_reviews.csv')\n",
    "hdm_omm_df = pd.read_csv('online_medien_management_hdm_reviews.csv')\n",
    "macromedia_df = pd.read_csv('medien_und_kommunikationsmanagement_macromedia_hochschule_reviews.csv')\n",
    "hdm_mw_df = pd.read_csv('digital_und_medienwirtschaft_hdm_reviews.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Füge eine Spalte für den Studiengang hinzu\n",
    "mittweida_df['Studiengang'] = 'Mittweida'\n",
    "hdm_omm_df['Studiengang'] = 'OMM'\n",
    "macromedia_df['Studiengang'] = 'Macromedia'\n",
    "hdm_mw_df['Studiengang'] = 'DMW'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Kombiniere die DataFrames für die Analyse\n",
    "all_reviews_df = pd.concat([mittweida_df, hdm_omm_df, macromedia_df, hdm_mw_df], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Bereinige die Texte in den Reviews\n",
    "all_reviews_df['cleaned_review'] = all_reviews_df['Review'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Lade das deutsche Sprachmodell und füge die SpacyTextBlob-Komponente hinzu\n",
    "nlp = spacy.load('de_core_news_sm')\n",
    "spacy_text_blob = SpacyTextBlob(nlp)\n",
    "nlp.add_pipe('spacytextblob')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Sentiment-Analyse-Funktion\n",
    "def get_sentiment(text):\n",
    "    doc = nlp(text)\n",
    "    return doc._.polarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Führe die Sentiment-Analyse durch\n",
    "all_reviews_df['sentiment'] = all_reviews_df['cleaned_review'].apply(get_sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Überprüfung der Sentiment-Analyse durch manuelle Überprüfung einiger Beispiele\n",
    "print(\"Manuelle Überprüfung einiger Bewertungen:\")\n",
    "print(all_reviews_df[(all_reviews_df['sentiment'] < 0)].head(10)['Review'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Positive und negative Bewertungen trennen und Wortwolken erstellen\n",
    "for studiengang in all_reviews_df['Studiengang'].unique():\n",
    "    pos_reviews = ' '.join(all_reviews_df[(all_reviews_df['Studiengang'] == studiengang) & (all_reviews_df['sentiment'] > 0)]['cleaned_review'])\n",
    "    neg_reviews = ' '.join(all_reviews_df[(all_reviews_df['Studiengang'] == studiengang) & (all_reviews_df['sentiment'] < 0)]['cleaned_review'])\n",
    "    \n",
    "    # Wortwolke für positive Bewertungen\n",
    "    generate_wordcloud(pos_reviews, f'{studiengang} - Positive Reviews')\n",
    "    \n",
    "    # Wortwolke für negative Bewertungen\n",
    "    generate_wordcloud(neg_reviews, f'{studiengang} - Negative Reviews')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Kategorisierung der Bewertungen\n",
    "categories = ['Dozenten', 'Technik', 'Ausstattung', 'Organisation', 'Praxisbezug']\n",
    "category_keywords = {\n",
    "    'Dozenten': ['dozent', 'professor', 'lehrkraft'],\n",
    "    'Technik': ['technik', 'computer', 'software', 'hardware'],\n",
    "    'Ausstattung': ['ausstattung', 'raum', 'labor', 'bibliothek'],\n",
    "    'Organisation': ['organisation', 'verwaltung', 'koordinierung'],\n",
    "    'Praxisbezug': ['praxis', 'projekt', 'praktikum', 'anwendung']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion zur Kategorisierung der Bewertungen\n",
    "def categorize_review(review):\n",
    "    for category, keywords in category_keywords.items():\n",
    "        if any(keyword in review.lower() for keyword in keywords):\n",
    "            return category\n",
    "    return 'Sonstiges'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_reviews_df['category'] = all_reviews_df['cleaned_review'].apply(categorize_review)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Durchschnittliches Sentiment pro Kategorie und Studiengang\n",
    "category_sentiment = all_reviews_df.groupby(['Studiengang', 'category'])['sentiment'].mean().unstack()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Visualisierung der durchschnittlichen Sentiments pro Kategorie und Studiengang mit Altair\n",
    "category_sentiment_reset = category_sentiment.reset_index().melt(id_vars='Studiengang', var_name='Kategorie', value_name='Sentiment')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bar_chart = alt.Chart(category_sentiment_reset).mark_bar().encode(\n",
    "    x=alt.X('Kategorie:N', title='Kategorie'),\n",
    "    y=alt.Y('Sentiment:Q', title='Durchschnittliches Sentiment'),\n",
    "    color='Studiengang:N',\n",
    "    column='Studiengang:N'\n",
    ").properties(\n",
    "    title='Durchschnittliches Sentiment pro Kategorie und Studiengang'\n",
    ").configure_title(\n",
    "    fontSize=20,\n",
    "    anchor='start',\n",
    "    color='gray'\n",
    ").configure_axis(\n",
    "    labelFontSize=12,\n",
    "    titleFontSize=14\n",
    ")\n",
    "\n",
    "bar_chart.display()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Relative Gegenüberstellung der Bewertungen\n",
    "relative_strengths = all_reviews_df.groupby(['Studiengang', 'category'])['sentiment'].mean().unstack().rank(axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Visualisierung der relativen Stärken und Schwächen mit Altair\n",
    "relative_strengths_reset = relative_strengths.reset_index().melt(id_vars='Studiengang', var_name='Kategorie', value_name='Rang')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "heatmap = alt.Chart(relative_strengths_reset).mark_rect().encode(\n",
    "    x=alt.X('Kategorie:N', title='Kategorie'),\n",
    "    y=alt.Y('Studiengang:N', title='Studiengang'),\n",
    "    color=alt.Color('Rang:Q', scale=alt.Scale(domain=[1, 4], range=['red', 'green']), title='Rang'),\n",
    "    tooltip=['Studiengang', 'Kategorie', 'Rang']\n",
    ").properties(\n",
    "    title='Relative Stärken und Schwächen pro Kategorie und Studiengang'\n",
    ").configure_title(\n",
    "    fontSize=20,\n",
    "    anchor='start',\n",
    "    color='gray'\n",
    ").configure_axis(\n",
    "    labelFontSize=12,\n",
    "    titleFontSize=14\n",
    ").encode(\n",
    "    text=alt.Text('Rang:Q')\n",
    ")\n",
    "\n",
    "heatmap.display()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Speichere die Ergebnisse in einer CSV-Datei\n",
    "all_reviews_df.to_csv('all_reviews_with_sentiment_and_categories.csv', index=False)\n",
    "print(\"Analyse abgeschlossen und Ergebnisse gespeichert.\")\n",
    "\n",
    "# Interpretationen der Ergebnisse\n",
    "interpretations = \"\"\"\n",
    "### Interpretation der Ergebnisse:\n",
    "\n",
    "#### Sentiment-Analyse:\n",
    "Die Sentiment-Analyse ergab gemischte Ergebnisse mit positiven und negativen Bewertungen. Die manuelle Überprüfung einiger als negativ eingestufter Bewertungen zeigt, dass nicht alle Bewertungen, die als negativ eingestuft wurden, tatsächlich negativen Inhalt haben. Dies könnte auf die Tücken der Sentiment-Analyse hinweisen, insbesondere bei der Verarbeitung von Ironie oder komplexen Sätzen.\n",
    "\n",
    "#### Durchschnittliches Sentiment pro Kategorie und Studiengang:\n",
    "Die Visualisierung des durchschnittlichen Sentiments pro Kategorie und Studiengang zeigt deutliche Unterschiede zwischen den Studiengängen. Beispielsweise:\n",
    "- **OMM**: Zeigt insgesamt positive Bewertungen, insbesondere in den Kategorien Dozenten und Praxisbezug.\n",
    "- **Mittweida**: Hat relativ ausgewogene Bewertungen, aber Schwächen in der Kategorie Organisation.\n",
    "\n",
    "#### Relative Stärken und Schwächen:\n",
    "Die Heatmap zur relativen Analyse zeigt, wie die einzelnen Studiengänge im Vergleich zu den anderen in den verschiedenen Kategorien abschneiden. Ein hoher Rang deutet auf relative Stärken hin, während ein niedriger Rang auf relative Schwächen hinweist.\n",
    "- **OMM**: Hat relative Stärken in der Kategorie Dozenten und Praxisbezug.\n",
    "\"\"\"\n",
    "\n",
    "print(interpretations)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
