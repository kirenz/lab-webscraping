{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment-Analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import der erforderlichen Bibliotheken gemäß PEP8\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Herunterladen der NLTK-Ressourcen\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Zusätzliche Stopwörter definieren\n",
    "additional_stopwords = set([\n",
    "    'studium', 'studiengang', 'hochschule', 'uni', 'universität', 'semester', \n",
    "    'student', 'studieren', 'studierende', 'fach', 'lehrveranstaltung', 'professor', \n",
    "    'dozent', 'viele', 'dabei', 'ab', 'jedoch', 'auch', 'immer', 'während', 'mehr', \n",
    "    'bisher', 'obwohl', 'zudem', 'hochschule', 'studium', 'studiengang', 'semester', 'erfahrungsbericht', \n",
    "    'weiterlesen', 'dozenten', 'gut', 'viele', 'immer', 'gibt', 'hdm', \n",
    "    'macromedia', 'mittweida', 'vorlesungen',  'aber', 'alle', 'allem', 'allen', 'aller', 'alles', 'als', 'also', 'am', 'an', 'ander', 'andere', \n",
    "    'anderem', 'anderen', 'anderer', 'anderes', 'anderm', 'andern', 'anderr', 'anders', 'auch', \n",
    "    'auf', 'aus', 'bei', 'bin', 'bis', 'bist', 'da', 'damit', 'dann', 'der', 'den', 'des', 'dem', \n",
    "    'die', 'das', 'dass', 'daß', 'derselbe', 'derselben', 'denselben', 'desselben', 'demselben', \n",
    "    'dieselbe', 'dieselben', 'dasselbe', 'dazu', 'dein', 'deine', 'deinem', 'deinen', 'deiner', \n",
    "    'deines', 'denn', 'derer', 'dessen', 'dich', 'dir', 'du', 'dies', 'diese', 'diesem', 'diesen', \n",
    "    'dieser', 'dieses', 'doch', 'dort', 'durch', 'ein', 'eine', 'einem', 'einen', 'einer', 'eines', \n",
    "    'einig', 'einige', 'einigem', 'einigen', 'einiger', 'einiges', 'einmal', 'er', 'ihn', 'ihm', \n",
    "    'es', 'etwas', 'euer', 'eure', 'eurem', 'euren', 'eurer', 'eures', 'für', 'gegen', 'gewesen', \n",
    "    'hab', 'habe', 'haben', 'hat', 'hatte', 'hatten', 'hier', 'hin', 'hinter', 'ich', 'mich', \n",
    "    'mir', 'ihr', 'ihre', 'ihrem', 'ihren', 'ihrer', 'ihres', 'euch', 'im', 'in', 'indem', 'ins', \n",
    "    'ist', 'jede', 'jedem', 'jeden', 'jeder', 'jedes', 'jene', 'jenem', 'jenen', 'jener', 'jenes', \n",
    "    'jetzt', 'kann', 'kein', 'keine', 'keinem', 'keinen', 'keiner', 'keines', 'können', 'könnte', \n",
    "    'machen', 'man', 'manche', 'manchem', 'manchen', 'mancher', 'manches', 'mein', 'meine', \n",
    "    'meinem', 'meinen', 'meiner', 'meines', 'mit', 'muss', 'musste', 'nach', 'nicht', 'nichts', \n",
    "    'noch', 'nun', 'nur', 'ob', 'oder', 'ohne', 'sehr', 'sein', 'seine', 'seinem', 'seinen', \n",
    "    'seiner', 'seines', 'selbst', 'sich', 'sie', 'ihnen', 'sind', 'so', 'solche', 'solchem', \n",
    "    'solchen', 'solcher', 'solches', 'soll', 'sollte', 'sondern', 'sonst', 'über', 'um', 'und', \n",
    "    'uns', 'unsere', 'unserem', 'unseren', 'unser', 'unseres', 'unter', 'viel', 'vom', 'von', \n",
    "    'vor', 'während', 'war', 'waren', 'warst', 'was', 'weg', 'weil', 'weiter', 'welche', 'welchem', \n",
    "    'welchen', 'welcher', 'welches', 'wenn', 'werde', 'werden', 'wie', 'wieder', 'will', 'wir', \n",
    "    'wird', 'wirst', 'wo', 'wollen', 'wollte', 'würde', 'würden', 'zu', 'zum', 'zur', 'zwar', \n",
    "    'zwischen'\n",
    "])\n",
    "\n",
    "# Hinzufügen der neuen Stopwörter\n",
    "additional_stopwords.update([\n",
    "    'wirklich', 'lernt', 'spaß', 'vielen', 'macht', 'professoren', 'erfahrungen', \n",
    "    'schon', 'lehrveranstaltungen', 'interessant', 'wissen', 'studiums', 'verschiedene', \n",
    "    'allerdings', 'zufrieden', 'bereich', 'einfach', 'möglichkeit', 'lernen', 'top', \n",
    "    'theorie', 'bekommt', 'arbeiten', 'teilweise', 'kompetent', 'mal', 'themen', 'zeit', \n",
    "    'studieninhalte', 'gemacht', 'module', 'oft', 'tolle', 'besonders', 'denen', 'wurde', \n",
    "    'erfahrung', 'dafür', 'management', 'empfehlen', 'konnte', 'meisten', 'ausgestattet', \n",
    "    'außerdem', 'möchte', 'grundlagen', 'eher', 'gerade', 'fragen', 'dadurch', \n",
    "    'super', 'medien', 'projekte', 'studenten', 'gute', 'inhalte', 'organisation', \n",
    "    'leider', 'bietet', 'praxis', 'möglichkeiten', 'ausstattung', 'ersten', 'bwl', \n",
    "    'projekten', 'medienmanagement', 'campus', 'online', 'auslandssemester', \n",
    "    'grundstudium', 'medienwirtschaft', 'marketing', 'kurse', 'schnell', 'gestaltet', \n",
    "    'kommt', 'technik', 'veranstaltungen', 'sagen', 'bereichen', 'praxisnah', \n",
    "    'wenig', 'besser', 'neben', 'semestern', 'später', 'ganz', 'studierenden', \n",
    "    'berufsleben', 'vermittelt', 'natürlich', 'direkt', 'erst', 'finde', 'geht', \n",
    "    'praktische', 'kommen', 'medienbranche', 'richtung', 'gehen', 'bereiche', 'wer', 'stets',\n",
    "    'fast', 'bereit', 'sammeln', 'große', 'lässt', 'richtig', 'richtige', 'genau', 'neue', 'bringen',\n",
    "    'leben', 'wählen', 'etc', 'erhält', 'gab', 'möglich', 'bekommen', 'hauptstudium',\n",
    "    'eigenen', 'einblick', 'fühlt', 'vertiefung', 'omm', 'mhmk', 'echt'\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Textbereinigungsfunktion\n",
    "def clean_text(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('german')]\n",
    "    tokens = [word for word in tokens if word not in additional_stopwords]\n",
    "    tokens = [word for word in tokens if word.isalnum()]\n",
    "    return ' '.join(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Funktion zur Generierung von Wortwolken\n",
    "def generate_wordcloud(text, title):\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Lade die CSV-Dateien\n",
    "mittweida_df = pd.read_csv('medienmanagement_mittweida_reviews.csv')\n",
    "hdm_omm_df = pd.read_csv('online_medien_management_hdm_reviews.csv')\n",
    "macromedia_df = pd.read_csv('medien_und_kommunikationsmanagement_macromedia_hochschule_reviews.csv')\n",
    "hdm_mw_df = pd.read_csv('digital_und_medienwirtschaft_hdm_reviews.csv')\n",
    "\n",
    "# Füge eine Spalte für den Studiengang hinzu\n",
    "mittweida_df['Studiengang'] = 'Mittweida'\n",
    "hdm_omm_df['Studiengang'] = 'OMM'\n",
    "macromedia_df['Studiengang'] = 'Macromedia'\n",
    "hdm_mw_df['Studiengang'] = 'DMW'\n",
    "\n",
    "# Kombiniere die DataFrames für die Analyse\n",
    "all_reviews_df = pd.concat([mittweida_df, hdm_omm_df, macromedia_df, hdm_mw_df], ignore_index=True)\n",
    "\n",
    "# Bereinige die Texte in den Reviews\n",
    "all_reviews_df['cleaned_review'] = all_reviews_df['Review'].apply(clean_text)\n",
    "\n",
    "# Generiere eine Wortwolke pro Studiengang\n",
    "for studiengang in all_reviews_df['Studiengang'].unique():\n",
    "    studiengang_reviews = ' '.join(all_reviews_df[all_reviews_df['Studiengang'] == studiengang]['cleaned_review'])\n",
    "    generate_wordcloud(studiengang_reviews, f'{studiengang} - Häufigste Begriffe nach Bereinigung')\n",
    "\n",
    "# Speichere die bereinigten Daten in einer CSV-Datei\n",
    "all_reviews_df.to_csv('all_reviews_cleaned_v2.csv', index=False)\n",
    "print(\"Analyse abgeschlossen und Ergebnisse gespeichert.\")\n",
    "\n",
    "# Funktion zur Extraktion der häufigsten Begriffe\n",
    "def get_top_terms(text, top_n=10):\n",
    "    tokens = word_tokenize(text)\n",
    "    counter = Counter(tokens)\n",
    "    most_common = counter.most_common(top_n)\n",
    "    return pd.DataFrame(most_common, columns=['Begriff', 'Häufigkeit'])\n",
    "\n",
    "# Erstelle eine DataFrame für die wichtigsten Begriffe pro Studiengang\n",
    "top_terms_per_studiengang = pd.DataFrame()\n",
    "\n",
    "for studiengang in all_reviews_df['Studiengang'].unique():\n",
    "    studiengang_reviews = ' '.join(all_reviews_df[all_reviews_df['Studiengang'] == studiengang]['cleaned_review'])\n",
    "    top_terms = get_top_terms(studiengang_reviews, top_n=10)\n",
    "    top_terms['Studiengang'] = studiengang\n",
    "    top_terms_per_studiengang = pd.concat([top_terms_per_studiengang, top_terms], ignore_index=True)\n",
    "\n",
    "# Zeige die Tabelle als pandas DataFrame an\n",
    "top_terms_per_studiengang"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
